{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport time\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler\nfrom imblearn.under_sampling import RandomUnderSampler\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-21T01:30:19.353793Z","iopub.execute_input":"2024-07-21T01:30:19.354485Z","iopub.status.idle":"2024-07-21T01:30:19.359536Z","shell.execute_reply.started":"2024-07-21T01:30:19.354455Z","shell.execute_reply":"2024-07-21T01:30:19.358649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:30:19.376529Z","iopub.execute_input":"2024-07-21T01:30:19.376845Z","iopub.status.idle":"2024-07-21T01:30:19.381476Z","shell.execute_reply.started":"2024-07-21T01:30:19.376820Z","shell.execute_reply":"2024-07-21T01:30:19.380572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load and preprocess data\n\nThe dataset was loaded with optimized data types to reduce memory usage, and unnecessary columns, such as the 'id' column, were removed. This step ensures efficient data processing for further analysis, which is crucial for handling large datasets in real-world applications, where memory optimization is key for smooth operation.\n","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\ndtypes = {\n    'Gender': 'category',\n    'Driving_License': 'category',\n    'Previously_Insured': 'category',\n    'Vehicle_Age': 'category',\n    'Vehicle_Damage': 'category',\n    'Region_Code': 'category',\n    'Policy_Sales_Channel': 'category',\n    'Age': 'int8',\n    'Vintage': 'int16',\n    'Annual_Premium': 'float32'\n}\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s4e7/train.csv', dtype=dtypes)\ntest = pd.read_csv('/kaggle/input/playground-series-s4e7/test.csv', dtype=dtypes)\n\ntrain.columns = train.columns.str.strip()\ntest.columns = test.columns.str.strip()\n\ntrain.drop(columns=['id'], inplace=True)\n\ntest_ids = test['id']\ntest.drop(columns=['id'], inplace=True)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Time load: {elapsed_time:.2f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:30:19.383690Z","iopub.execute_input":"2024-07-21T01:30:19.384073Z","iopub.status.idle":"2024-07-21T01:30:45.618379Z","shell.execute_reply.started":"2024-07-21T01:30:19.384043Z","shell.execute_reply":"2024-07-21T01:30:45.617454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering and preprocessing\n\nCategorical variables, like `Vehicle_Age`, were transformed into numerical values to enhance model interpretability. \n\nThe train and test sets were temporarily combined to apply uniform transformations across both datasets. \n\nProper feature engineering improves model performance by providing structured, meaningful data for the model to learn from.\n\nThe feature engineering approach in this notebook is adapted from the work that Khang and I contributed together in our team's  [EDA_Classification_Insurance](https://www.kaggle.com/code/khangtran94vn/eda-classification-insurance/notebook) notebook. ","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n\ntest['Response'] = 0\ntest['Response'] = test['Response'].astype('int64')\n\ncb = pd.concat([train, test]) #combined\n\n# Encode categorical variables\nvehicle_age_order = {\"< 1 Year\": 0, \"1-2 Year\": 1, \"> 2 Years\": 2}\ncb[\"Vehicle_Age\"] = cb[\"Vehicle_Age\"].astype('category').cat.set_categories(vehicle_age_order.keys()).cat.rename_categories(vehicle_age_order).astype('int8')\n\nvehicle_damage = {'No':0, 'Yes':1}\ncb[\"Vehicle_Damage\"] = cb[\"Vehicle_Damage\"].astype('category').cat.set_categories(vehicle_damage.keys()).cat.rename_categories(vehicle_damage).astype('int8')\n\ncategorical_columns = ['Gender', 'Driving_License', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Region_Code', 'Policy_Sales_Channel']\nlabel_encoders = {col: LabelEncoder() for col in categorical_columns}\nfor col in categorical_columns:\n    cb[col] = label_encoders[col].fit_transform(cb[col])\n\n# Convert datatypes to save memory\ncb['Gender'] = cb['Gender'].astype('int8')\ncb['Vehicle_Age'] = cb['Vehicle_Age'].astype('int8')\ncb['Vehicle_Damage'] = cb['Vehicle_Damage'].astype('int8')\ncb['Driving_License'] = cb['Driving_License'].astype('int8')\ncb['Previously_Insured'] = cb['Previously_Insured'].astype('int8')\ncb['Region_Code'] = cb['Region_Code'].astype('int8')\ncb['Policy_Sales_Channel'] = cb['Policy_Sales_Channel'].astype('int16')\n\n# Create interaction features\ncb['Insured_Annual_Premium'] = pd.factorize(cb['Previously_Insured'].astype(str) + cb['Annual_Premium'].astype(str))[0]\ncb['Insured_Vehicle_Age'] = pd.factorize(cb['Previously_Insured'].astype(str) + cb['Vehicle_Age'].astype(str))[0]\ncb['Insured_Vehicle_Damage'] = pd.factorize(cb['Previously_Insured'].astype(str) + cb['Vehicle_Damage'].astype(str))[0]\ncb['Insured_Vintage'] = pd.factorize(cb['Previously_Insured'].astype(str) + cb['Vintage'].astype(str))[0]\n\ntrain = cb.iloc[:len(train)]\ntest = cb.iloc[len(train):]\ntest = test.drop(columns=['Response'])\n\ndel cb\ngc.collect()\ntrain.head()\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(f\"Time load: {elapsed_time:.2f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:30:45.620058Z","iopub.execute_input":"2024-07-21T01:30:45.620544Z","iopub.status.idle":"2024-07-21T01:32:43.518455Z","shell.execute_reply.started":"2024-07-21T01:30:45.620510Z","shell.execute_reply":"2024-07-21T01:32:43.517471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling\n\n### Cross-Validation\nClass imbalance in the target variable was addressed using RandomUnderSampler to create a balanced view of both classes. \n\nThis approach prevents model bias toward the majority class and improves generalization to the minority class, which is critical when dealing with imbalanced data often found in real-world scenarios.\n\n### Model Evaluation Using ROC-AUC\nStratified K-Fold cross-validation with XGBoost was employed to ensure consistent class distribution across folds. \n\nCross-validation reduces overfitting by training the model on different subsets of data, providing a more reliable estimate of the model's performance on unseen data.","metadata":{}},{"cell_type":"code","source":"# Define training function with cross-validation and bagging\ndef train_cv(X, y, n_splits=10, n_bags=8):\n    params = {\n        'objective': 'binary:logistic',\n        'eval_metric': 'auc',\n        'learning_rate': 0.18346215360183396,\n        'n_estimators': 2413,\n        'max_depth': 6,\n        'max_bin': 93101,\n        'reg_alpha': 1.4244811420186621e-06, \n        'reg_lambda': 1.1488485490280707,\n        'tree_method': 'gpu_hist',  \n        'predictor': 'gpu_predictor',\n        'seed': 42,\n        'verbosity': 0\n    }\n    \n    start_time = time.time()\n    \n    best_auc = 0\n    best_model = None\n    best_scaler = None\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    oof_preds = np.zeros(len(y))\n    \n    scores = []\n\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n        print(f\"Fold #{fold + 1}\")\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        fold_predictions = np.zeros(len(y_test))\n        \n        fold_models = []\n        fold_scalers = []\n        \n        for bag in range(n_bags):\n            print(f\"Bag #{bag + 1}\")\n            \n            # Progressive sampling strategy\n            sample_size = int(len(X_train) * (bag + 1) / n_bags)\n            \n            minority_count = (y_train == y_train.min()).sum()\n            majority_count = len(y_train) - minority_count\n            sampling_ratio = min(0.5, minority_count / (sample_size / 2))  \n            sampling_strategy = {y_train.min(): int(sample_size * sampling_ratio),\n                                 y_train.max(): sample_size - int(sample_size * sampling_ratio)}\n            \n            undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42+bag)\n            X_sampled, y_sampled = undersampler.fit_resample(X_train, y_train)\n            \n            # Feature scaling\n            scaler = RobustScaler()\n            X_sampled_scaled = scaler.fit_transform(X_sampled)\n            X_test_scaled = scaler.transform(X_test)\n            \n            model = xgb.XGBClassifier(**params)\n            model.fit(X_sampled_scaled, y_sampled, \n                      eval_set=[(X_test_scaled, y_test)], \n                      verbose=False)\n            \n            y_pred = model.predict_proba(X_test_scaled)[:, 1]\n            fold_predictions += y_pred / n_bags\n            \n            bag_auc = roc_auc_score(y_test, y_pred)\n\n            print(f\"ROC-AUC-Score={bag_auc:.7f}\")\n            \n            scores.append(bag_auc)\n            fold_models.append(model)\n            fold_scalers.append(scaler)\n\n            del X_sampled_scaled, X_test_scaled\n            gc.collect()\n            \n        oof_preds[test_index] = fold_predictions\n\n        # Average the predictions from all bags\n        fold_auc = roc_auc_score(y_test, fold_predictions) \n        print(f\"Aggregated AUC score for Fold #{fold + 1}: {fold_auc:.7f}\")\n        \n        if fold_auc > best_auc:\n            best_auc = fold_auc\n            best_models = fold_models\n            best_scalers = fold_scalers\n    \n    overall_auc = roc_auc_score(y, oof_preds)\n    print(f\"Overall AUC score: {overall_auc:.7f}\")\n    \n    print(f\"ROC-AUC mean: {np.array(scores).mean():.7f} (+- {np.array(scores).std():.7f})\")\n    \n    total_auc = roc_auc_score(y, oof_preds)\n    print(f\"Total ROC-AUC score: {total_auc}\")\n\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n    print(f\"Time load: {elapsed_time:.2f} seconds\")\n    return best_models, best_scalers","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:32:43.519954Z","iopub.execute_input":"2024-07-21T01:32:43.520218Z","iopub.status.idle":"2024-07-21T01:32:43.536459Z","shell.execute_reply.started":"2024-07-21T01:32:43.520195Z","shell.execute_reply":"2024-07-21T01:32:43.535578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble Model Prediction\n\nThe `ensemble_predict` function averages predictions from multiple models using their respective scalers. It processes the test data, scales it, and computes the mean prediction probabilities across the models. The final predictions are returned.\n\n- **X and y split**: Separates features (X) and target (y) from the training dataset.\n- **Best models and scalers**: Trains the models with cross-validation, finding the best models and scalers.","metadata":{}},{"cell_type":"code","source":"def ensemble_predict(test, models, scalers):\n    preds = np.zeros(len(test))\n    for model, scaler in zip(models, scalers):\n        test_scaled = scaler.transform(test)\n        preds += model.predict_proba(test_scaled)[:, 1]\n    final_preds = preds / len(models)\n    return final_preds","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:32:43.538636Z","iopub.execute_input":"2024-07-21T01:32:43.539051Z","iopub.status.idle":"2024-07-21T01:32:43.553688Z","shell.execute_reply.started":"2024-07-21T01:32:43.539025Z","shell.execute_reply":"2024-07-21T01:32:43.552967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns=['Response'])\ny = train['Response']","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:32:43.554758Z","iopub.execute_input":"2024-07-21T01:32:43.555028Z","iopub.status.idle":"2024-07-21T01:32:44.060649Z","shell.execute_reply.started":"2024-07-21T01:32:43.554996Z","shell.execute_reply":"2024-07-21T01:32:44.058790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_models, best_scalers = train_cv(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:32:44.062230Z","iopub.execute_input":"2024-07-21T01:32:44.062603Z","iopub.status.idle":"2024-07-21T01:34:29.479266Z","shell.execute_reply.started":"2024-07-21T01:32:44.062569Z","shell.execute_reply":"2024-07-21T01:34:29.478290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"final_preds = ensemble_predict(test, best_models, best_scalers)\n\nsubmission = pd.DataFrame({\n    'id': test_ids,\n    'Response': final_preds\n})\n\n# save the submission file\nsubmission.to_csv('submission.csv', index=False)\nprint('submission ready!')","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:34:29.480505Z","iopub.execute_input":"2024-07-21T01:34:29.480831Z","iopub.status.idle":"2024-07-21T01:34:58.449181Z","shell.execute_reply.started":"2024-07-21T01:34:29.480803Z","shell.execute_reply":"2024-07-21T01:34:58.448203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T01:34:58.450374Z","iopub.execute_input":"2024-07-21T01:34:58.450694Z","iopub.status.idle":"2024-07-21T01:34:58.460642Z","shell.execute_reply.started":"2024-07-21T01:34:58.450668Z","shell.execute_reply":"2024-07-21T01:34:58.459771Z"},"trusted":true},"execution_count":null,"outputs":[]}]}